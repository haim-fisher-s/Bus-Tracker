{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy ver.: 1.13.1\n",
      "pandas ver.: 0.19.0\n",
      "tensorflow ver.: 1.0.0\n",
      "keras ver.: 2.0.8\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import CSVLogger, EarlyStopping\n",
    "import keras.backend.tensorflow_backend as ktf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common import *\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'w'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "plt.rcParams['axes.edgecolor'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['grid.color'] = (.7, .7, .7, 0)\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "print('numpy ver.: ' + np.__version__)\n",
    "print('pandas ver.: ' + pd.__version__)\n",
    "print('tensorflow ver.: ' + tf.__version__) \n",
    "print('keras ver.: ' + keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_session(gpu_fraction=1):\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction,\n",
    "                                allow_growth=True)\n",
    "    return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "ktf.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Functions for generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_timesteps, output_timesteps, num_links):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_links, 1, 1)))\n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_1',\n",
    "                         filters = 64, kernel_size = (5, 1),                       \n",
    "                         padding = 'same', \n",
    "                         return_sequences = True))\n",
    "    \n",
    "    model.add(Dropout(0.2, name = 'dropout_1'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_1'))\n",
    "\n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_2',\n",
    "                         filters = 64, kernel_size = (5, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = False))\n",
    "    \n",
    "    model.add(Dropout(0.1, name = 'dropout_2'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_2'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(output_timesteps))\n",
    "    model.add(Reshape((output_timesteps, num_links, 1, 64)))\n",
    "    \n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_3',\n",
    "                         filters = 64, kernel_size = (5, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = True))\n",
    "    \n",
    "    model.add(Dropout(0.1, name = 'dropout_3'))\n",
    "    model.add(BatchNormalization(name = 'batch_norm_3'))\n",
    "    \n",
    "    model.add(ConvLSTM2D(name ='conv_lstm_4',\n",
    "                         filters = 64, kernel_size = (5, 1), \n",
    "                         padding='same',\n",
    "                         return_sequences = True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(units=1, name = 'dense_1', activation = 'relu')))\n",
    "    #model.add(Dense(units=1, name = 'dense_2'))\n",
    "\n",
    "    optimizer = RMSprop() #lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.9)\n",
    "    model.compile(loss = \"mse\", optimizer = optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def info(msg):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') + \" \" + msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103832\n"
     ]
    }
   ],
   "source": [
    "data = prep_data('../data/4A_1_201705_201709.csv')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Subset the part of the 4A line that are identical across all journey patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839495\n"
     ]
    }
   ],
   "source": [
    "data = data[(1 <= data['LineDirectionLinkOrder']) & (data['LineDirectionLinkOrder'] <= 32)]\n",
    "data = data[data['LinkTravelTime'].notnull()]\n",
    "assert len(data['LinkRef'].unique()) == 32\n",
    "n = len(data)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-12 09:02:45 Current window: 0\n",
      "2017-10-12 09:02:45 - Train size :   629621 (0.75%) \n",
      "2017-10-12 09:02:45 - Test size  :    41975 (0.05%) \n",
      "2017-10-12 09:02:46 - Removed 22506 outliers (3.57%) from train\n",
      "2017-10-12 09:02:46 - Removed 2197 outliers (5.23%) from test\n",
      "2017-10-12 09:02:48 - X_train shape : (11069, 32, 32, 1, 1)    X_test shape :  (707, 32, 32, 1, 1)\n",
      "2017-10-12 09:02:48 - Y_train shape : (11069, 3, 32, 1, 1)    Y_test shape :   (707, 3, 32, 1, 1)\n",
      "Train on 11069 samples, validate on 707 samples\n",
      "Epoch 1/30\n",
      "21s - loss: 0.4804 - val_loss: 0.5731\n",
      "Epoch 2/30\n",
      "19s - loss: 0.4731 - val_loss: 0.5730\n",
      "Epoch 3/30\n",
      "19s - loss: 0.4691 - val_loss: 0.5729\n",
      "Epoch 4/30\n",
      "19s - loss: 0.4661 - val_loss: 0.5730\n",
      "Epoch 5/30\n",
      "20s - loss: 0.4634 - val_loss: 0.5719\n",
      "Epoch 6/30\n",
      "20s - loss: 0.4609 - val_loss: 0.5718\n",
      "Epoch 7/30\n",
      "19s - loss: 0.4586 - val_loss: 0.5685\n",
      "Epoch 8/30\n",
      "19s - loss: 0.4559 - val_loss: 0.5692\n",
      "Epoch 9/30\n",
      "20s - loss: 0.4543 - val_loss: 0.5666\n",
      "Epoch 10/30\n",
      "19s - loss: 0.4528 - val_loss: 0.5671\n",
      "Epoch 11/30\n",
      "20s - loss: 0.4498 - val_loss: 0.5617\n",
      "Epoch 12/30\n",
      "20s - loss: 0.4475 - val_loss: 0.5652\n",
      "Epoch 13/30\n",
      "20s - loss: 0.4465 - val_loss: 0.5631\n",
      "Epoch 14/30\n",
      "20s - loss: 0.4440 - val_loss: 0.5612\n",
      "Epoch 15/30\n",
      "20s - loss: 0.4418 - val_loss: 0.5635\n",
      "Epoch 16/30\n",
      "19s - loss: 0.4404 - val_loss: 0.5637\n",
      "Epoch 17/30\n",
      "20s - loss: 0.4380 - val_loss: 0.5642\n",
      "2017-10-12 09:08:37 - t + 1 - HA       - MAE:  3.47 - RMSE:  5.32 - MAPE:  5.55\n",
      "2017-10-12 09:08:37 - t + 1 - ConvLSTM - MAE:  3.34 - RMSE:  4.78 - MAPE:  5.63\n",
      "2017-10-12 09:08:37 - t + 1 - *        - MAE: -0.13 - RMSE: -0.54 - MAPE:  0.08\n",
      "2017-10-12 09:08:37 - t + 2 - HA       - MAE:  3.48 - RMSE:  5.33 - MAPE:  5.55\n",
      "2017-10-12 09:08:37 - t + 2 - ConvLSTM - MAE:  3.47 - RMSE:  5.15 - MAPE:  5.66\n",
      "2017-10-12 09:08:37 - t + 2 - *        - MAE: -0.01 - RMSE: -0.18 - MAPE:  0.11\n",
      "2017-10-12 09:08:37 - t + 3 - HA       - MAE:  3.48 - RMSE:  5.33 - MAPE:  5.55\n",
      "2017-10-12 09:08:37 - t + 3 - ConvLSTM - MAE:  3.51 - RMSE:  5.27 - MAPE:  5.68\n",
      "2017-10-12 09:08:37 - t + 3 - *        - MAE:  0.02 - RMSE: -0.07 - MAPE:  0.13\n",
      "2017-10-12 09:08:37 Current window: 1\n",
      "2017-10-12 09:08:37 - Train size :   671596 (0.80%) \n",
      "2017-10-12 09:08:37 - Test size  :    41974 (0.05%) \n",
      "2017-10-12 09:08:38 - Removed 23737 outliers (3.53%) from train\n",
      "2017-10-12 09:08:38 - Removed 2375 outliers (5.66%) from test\n",
      "2017-10-12 09:08:40 - X_train shape : (11810, 32, 32, 1, 1)    X_test shape :  (664, 32, 32, 1, 1)\n",
      "2017-10-12 09:08:40 - Y_train shape : (11810, 3, 32, 1, 1)    Y_test shape :   (664, 3, 32, 1, 1)\n",
      "Train on 11810 samples, validate on 664 samples\n",
      "Epoch 1/30\n",
      "22s - loss: 0.4840 - val_loss: 0.5862\n",
      "Epoch 2/30\n",
      "21s - loss: 0.4747 - val_loss: 0.5862\n",
      "Epoch 3/30\n",
      "21s - loss: 0.4709 - val_loss: 0.5851\n",
      "Epoch 4/30\n",
      "21s - loss: 0.4682 - val_loss: 0.5823\n",
      "Epoch 5/30\n",
      "21s - loss: 0.4659 - val_loss: 0.5796\n",
      "Epoch 6/30\n",
      "21s - loss: 0.4639 - val_loss: 0.5777\n",
      "Epoch 7/30\n",
      "21s - loss: 0.4616 - val_loss: 0.5750\n",
      "Epoch 8/30\n",
      "21s - loss: 0.4598 - val_loss: 0.5696\n",
      "Epoch 9/30\n",
      "21s - loss: 0.4574 - val_loss: 0.5701\n",
      "Epoch 10/30\n",
      "21s - loss: 0.4558 - val_loss: 0.5711\n",
      "Epoch 11/30\n",
      "21s - loss: 0.4553 - val_loss: 0.5629\n",
      "Epoch 12/30\n",
      "21s - loss: 0.4518 - val_loss: 0.5636\n",
      "Epoch 13/30\n",
      "21s - loss: 0.4501 - val_loss: 0.5686\n",
      "Epoch 14/30\n",
      "21s - loss: 0.4496 - val_loss: 0.5653\n",
      "2017-10-12 09:13:48 - t + 1 - HA       - MAE:  3.49 - RMSE:  5.68 - MAPE:  5.11\n",
      "2017-10-12 09:13:48 - t + 1 - ConvLSTM - MAE:  3.11 - RMSE:  4.50 - MAPE:  4.97\n",
      "2017-10-12 09:13:48 - t + 1 - *        - MAE: -0.38 - RMSE: -1.18 - MAPE: -0.14\n",
      "2017-10-12 09:13:48 - t + 2 - HA       - MAE:  3.50 - RMSE:  5.70 - MAPE:  5.11\n",
      "2017-10-12 09:13:48 - t + 2 - ConvLSTM - MAE:  3.25 - RMSE:  4.85 - MAPE:  4.99\n",
      "2017-10-12 09:13:48 - t + 2 - *        - MAE: -0.25 - RMSE: -0.85 - MAPE: -0.12\n",
      "2017-10-12 09:13:48 - t + 3 - HA       - MAE:  3.53 - RMSE:  5.76 - MAPE:  5.12\n",
      "2017-10-12 09:13:48 - t + 3 - ConvLSTM - MAE:  3.37 - RMSE:  5.20 - MAPE:  5.03\n",
      "2017-10-12 09:13:48 - t + 3 - *        - MAE: -0.16 - RMSE: -0.56 - MAPE: -0.09\n",
      "2017-10-12 09:13:48 Current window: 2\n",
      "2017-10-12 09:13:48 - Train size :   713570 (0.85%) \n",
      "2017-10-12 09:13:48 - Test size  :    41975 (0.05%) \n",
      "2017-10-12 09:13:49 - Removed 25232 outliers (3.54%) from train\n",
      "2017-10-12 09:13:49 - Removed 2174 outliers (5.18%) from test\n",
      "2017-10-12 09:13:51 - X_train shape : (12508, 32, 32, 1, 1)    X_test shape :  (696, 32, 32, 1, 1)\n",
      "2017-10-12 09:13:51 - Y_train shape : (12508, 3, 32, 1, 1)    Y_test shape :   (696, 3, 32, 1, 1)\n",
      "Train on 12508 samples, validate on 696 samples\n",
      "Epoch 1/30\n",
      "23s - loss: 0.4850 - val_loss: 0.5276\n",
      "Epoch 2/30\n",
      "22s - loss: 0.4760 - val_loss: 0.5270\n",
      "Epoch 3/30\n",
      "22s - loss: 0.4713 - val_loss: 0.5272\n",
      "Epoch 4/30\n",
      "22s - loss: 0.4688 - val_loss: 0.5254\n",
      "Epoch 5/30\n",
      "22s - loss: 0.4659 - val_loss: 0.5222\n",
      "Epoch 6/30\n",
      "22s - loss: 0.4637 - val_loss: 0.5216\n",
      "Epoch 7/30\n",
      "22s - loss: 0.4615 - val_loss: 0.5195\n",
      "Epoch 8/30\n",
      "22s - loss: 0.4586 - val_loss: 0.5167\n",
      "Epoch 9/30\n",
      "22s - loss: 0.4571 - val_loss: 0.5139\n",
      "Epoch 10/30\n",
      "22s - loss: 0.4543 - val_loss: 0.5112\n",
      "Epoch 11/30\n",
      "22s - loss: 0.4530 - val_loss: 0.5104\n",
      "Epoch 12/30\n",
      "22s - loss: 0.4516 - val_loss: 0.5123\n",
      "Epoch 13/30\n",
      "22s - loss: 0.4487 - val_loss: 0.5159\n",
      "Epoch 14/30\n",
      "22s - loss: 0.4471 - val_loss: 0.5185\n",
      "2017-10-12 09:19:16 - t + 1 - HA       - MAE:  3.18 - RMSE:  4.86 - MAPE:  4.72\n",
      "2017-10-12 09:19:16 - t + 1 - ConvLSTM - MAE:  2.78 - RMSE:  3.89 - MAPE:  4.76\n",
      "2017-10-12 09:19:16 - t + 1 - *        - MAE: -0.40 - RMSE: -0.97 - MAPE:  0.04\n",
      "2017-10-12 09:19:16 - t + 2 - HA       - MAE:  3.18 - RMSE:  4.86 - MAPE:  4.72\n",
      "2017-10-12 09:19:16 - t + 2 - ConvLSTM - MAE:  2.87 - RMSE:  4.09 - MAPE:  4.74\n",
      "2017-10-12 09:19:16 - t + 2 - *        - MAE: -0.30 - RMSE: -0.76 - MAPE:  0.02\n",
      "2017-10-12 09:19:16 - t + 3 - HA       - MAE:  3.18 - RMSE:  4.86 - MAPE:  4.73\n",
      "2017-10-12 09:19:16 - t + 3 - ConvLSTM - MAE:  2.93 - RMSE:  4.19 - MAPE:  4.80\n",
      "2017-10-12 09:19:16 - t + 3 - *        - MAE: -0.25 - RMSE: -0.67 - MAPE:  0.06\n",
      "2017-10-12 09:19:16 Current window: 3\n",
      "2017-10-12 09:19:16 - Train size :   755545 (0.90%) \n",
      "2017-10-12 09:19:16 - Test size  :    41975 (0.05%) \n",
      "2017-10-12 09:19:17 - Removed 26355 outliers (3.49%) from train\n",
      "2017-10-12 09:19:17 - Removed 1694 outliers (4.04%) from test\n",
      "2017-10-12 09:19:20 - X_train shape : (13238, 32, 32, 1, 1)    X_test shape :  (673, 32, 32, 1, 1)\n",
      "2017-10-12 09:19:20 - Y_train shape : (13238, 3, 32, 1, 1)    Y_test shape :   (673, 3, 32, 1, 1)\n",
      "Train on 13238 samples, validate on 673 samples\n",
      "Epoch 1/30\n",
      "25s - loss: 0.4832 - val_loss: 0.5117\n",
      "Epoch 2/30\n",
      "23s - loss: 0.4772 - val_loss: 0.5100\n",
      "Epoch 3/30\n",
      "23s - loss: 0.4720 - val_loss: 0.5089\n",
      "Epoch 4/30\n",
      "23s - loss: 0.4683 - val_loss: 0.5072\n",
      "Epoch 5/30\n",
      "23s - loss: 0.4655 - val_loss: 0.5063\n",
      "Epoch 6/30\n",
      "23s - loss: 0.4631 - val_loss: 0.5050\n",
      "Epoch 7/30\n",
      "23s - loss: 0.4607 - val_loss: 0.5040\n",
      "Epoch 8/30\n"
     ]
    }
   ],
   "source": [
    "global_start_time = time.time()\n",
    "csv_logger = CSVLogger('logs/convlstm_training.log')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "bootstrap_size_pct = 0.75\n",
    "test_window_pct = 0.05\n",
    "max_iter = 5\n",
    "\n",
    "lags = 4 * 8\n",
    "preds = 3\n",
    "\n",
    "hist = []\n",
    "for i in range(max_iter):\n",
    "\n",
    "    info(\"Current window: \" + str(i))\n",
    "    \n",
    "    # Devide into test and train\n",
    "    data_train = data[:int((bootstrap_size_pct + i * test_window_pct) * n)]\n",
    "    data_test = data[int((bootstrap_size_pct + i * test_window_pct) * n):int((bootstrap_size_pct + (i + 1) * test_window_pct) * n)]\n",
    "    n_train = len(data_train)\n",
    "    n_test = len(data_test)\n",
    "    info('- Train size : {:>8} ({:.2f}%) '.format(n_train, 1. * n_train / n))\n",
    "    info('- Test size  : {:>8} ({:.2f}%) '.format(n_test, 1. * n_test / n))\n",
    "    \n",
    "    # Mean center and scale\n",
    "    (means, scales, low, upr) = fit_scale(data_train)\n",
    "    assert means.shape == (4 * 24 * 7, 32)\n",
    "    assert len(scales) == 32\n",
    "    assert low.shape == (4 * 24 * 7, 32)\n",
    "    assert upr.shape == (4 * 24 * 7, 32)\n",
    "    \n",
    "    data_train_no, n_outliers = remove_outliers(data_train, low, upr)\n",
    "    info('- Removed {0} outliers ({1:.2f}%) from train'.format(n_outliers, 100.0 * n_outliers / len(data_train)))\n",
    "    data_test_no, n_outliers = remove_outliers(data_test, low, upr)\n",
    "    info('- Removed {0} outliers ({1:.2f}%) from test'.format(n_outliers, 100.0 * n_outliers / len(data_test)))\n",
    "    \n",
    "    ix_train, ts_train, rm_mean_train, rm_scale_train, w_train, lns_train = transform(data_train_no, means, scales)\n",
    "    ix_test, ts_test, rm_mean_test, rm_scale_test, w_test, lns_test = transform(data_test_no, means, scales)\n",
    "\n",
    "    # Create rolling window tensor\n",
    "    X_train, Y_train, Y_ix_train, Y_rm_mean_train, Y_scale_train, Y_w_train = roll(ix_train, ts_train, rm_mean_train, rm_scale_train, w_train, lags, preds)\n",
    "    X_test, Y_test, Y_ix_test, Y_rm_mean_test, Y_scale_test, Y_w_test = roll(ix_test, ts_test, rm_mean_test, rm_scale_test, w_test, lags, preds)\n",
    "\n",
    "    X_train = X_train[:,:,:,np.newaxis,np.newaxis]\n",
    "    Y_train = Y_train[:,:,:,np.newaxis,np.newaxis]\n",
    "    X_test = X_test[:,:,:,np.newaxis,np.newaxis]\n",
    "    Y_test = Y_test[:,:,:,np.newaxis,np.newaxis]\n",
    "    \n",
    "    info('- X_train shape : {:>20}    X_test shape : {:>20}'.format(X_train.shape, X_test.shape))\n",
    "    info('- Y_train shape : {:>20}    Y_test shape : {:>20}'.format(Y_train.shape, Y_test.shape))\n",
    "    \n",
    "    model = build_model(lags, preds, len(lns_train))\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size = 256, epochs = 30,\n",
    "                        shuffle = False, validation_data = (X_test, Y_test),\n",
    "                        verbose = 2, callbacks = [csv_logger, early_stopping])\n",
    "    hist.append(history)\n",
    "    model.save('models/ConvLSTM_3x15min_5x64-5x64-5x64-5x64_' + str(i) + '.h5') \n",
    "\n",
    "    Y_true = Y_test.squeeze() * Y_scale_test + Y_rm_mean_test\n",
    "    Y_naive = Y_rm_mean_test\n",
    "    Y_pred = model.predict(X_test).squeeze() * Y_scale_test + Y_rm_mean_test\n",
    "        \n",
    "    Y_true_total = np.sum(Y_true * Y_w_test, axis = 2).squeeze()\n",
    "    Y_naive_total = np.sum(Y_naive * Y_w_test, axis = 2).squeeze()\n",
    "    Y_pred_total = np.sum(Y_pred * Y_w_test, axis = 2).squeeze()\n",
    "    \n",
    "    for t in range(preds):\n",
    "        mask = Y_true_total[:,t] > 0\n",
    "        Y_true_total_t = Y_true_total[mask, t] / 60\n",
    "        Y_naive_total_t = Y_naive_total[mask, t] / 60\n",
    "        Y_pred_total_t = Y_pred_total[mask, t] / 60  \n",
    "\n",
    "        error_naive_total_t = (Y_naive_total_t - Y_true_total_t)\n",
    "        error_lstm_total_t = (Y_pred_total_t - Y_true_total_t)\n",
    "\n",
    "        mae_ha = np.mean(np.abs(error_naive_total_t))\n",
    "        rmse_ha = np.sqrt(np.mean((error_naive_total_t)**2))\n",
    "        mape_ha = np.mean(np.abs(error_naive_total_t) / Y_true_total_t) * 100\n",
    "\n",
    "        mae_lstm = np.mean(np.abs(error_lstm_total_t))\n",
    "        rmse_lstm = np.sqrt(np.mean((error_lstm_total_t)**2))\n",
    "        mape_lstm = np.mean(np.abs(error_lstm_total_t) / Y_true_total_t) * 100\n",
    "        \n",
    "        info(\"- t + %d - HA       - MAE: %5.2f - RMSE: %5.2f - MAPE: %5.2f\" % (t + 1, mae_ha, rmse_ha, mape_ha))\n",
    "        info(\"- t + %d - ConvLSTM - MAE: %5.2f - RMSE: %5.2f - MAPE: %5.2f\" % (t + 1, mae_lstm, rmse_lstm, mape_lstm))\n",
    "        info(\"- t + %d - *        - MAE: %5.2f - RMSE: %5.2f - MAPE: %5.2f\" % (t + 1, mae_lstm - mae_ha, rmse_lstm - rmse_ha, mape_lstm - mape_ha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for history in hist:\n",
    "    plt.plot(history.history['loss'])\n",
    "for history in hist:\n",
    "    plt.plot(history.history['val_loss'], linestyle = '--')\n",
    "    \n",
    "fig = plt.figure(figsize=(7, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(np.array(hist[-2].history['loss']) / 60)\n",
    "ax.plot(np.array(hist[-2].history['val_loss']) / 60, linestyle = '--')\n",
    "plt.ylabel('loss (min)', fontsize = 14)\n",
    "plt.xlabel('epoch', fontsize = 14)\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "#plt.show()\n",
    "fig.savefig('conv_lstm_model_loss.pdf')\n",
    "#fig.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
